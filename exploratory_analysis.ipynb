{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac53736-3a00-443d-9120-a37ee038a592",
   "metadata": {},
   "source": [
    "# MaSim Analysis and Interaction\n",
    "\n",
    "This notebook is used for testing and interacting with the output from MaSim as well as working with the input data. Once sufficiently developed, code from this notebook is converted to a Python module or script and moved into the `src/masim_analysis` or `scripts` directory. The source folder is for code that is intended to be used in other code, while the scripts folder is for code that is intended to be run from the command line. The source code may also define command line tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b639d9d9",
   "metadata": {},
   "source": [
    "## Some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08daa6a0-f860-43e1-be4f-cc107e0a09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from masim_analysis import analysis\n",
    "\n",
    "# DATA_ROOT: str = os.path.join(\"G:\\\\\", \"My Drive\")\n",
    "DATA_ROOT: str = os.path.join(\"/\", \"home\", \"james\", \"Code\", \"Temple-Malaria-Simulation-Analysis\")\n",
    "# DATA_SOURCE: str = os.path.join(DATA_ROOT, \"Code\", \"output_old\")\n",
    "DATA_SOURCE: str = os.path.join(DATA_ROOT, \"output2\", \"rwa\")\n",
    "filelist = glob.glob(os.path.join(DATA_SOURCE, \"*.db\"))\n",
    "\n",
    "strategies = [\n",
    "    \"AL5\",\n",
    "    \"AL4\",\n",
    "    \"AL25-ASAQ75\",\n",
    "    \"AL25-DHAPPQ75\",\n",
    "    \"AL50-ASAQ50\",\n",
    "    \"AL50-DHAPPQ50\",\n",
    "    \"AL75-ASAQ25\",\n",
    "    \"AL75-DHAPPQ25\",\n",
    "    \"ASAQ\",\n",
    "    \"ASAQ25-DHAPPQ75\",\n",
    "    \"ASAQ50-DHAPPQ50\",\n",
    "    \"ASAQ75-DHAPPQ25\",\n",
    "    \"DHA-PPQ\",\n",
    "    \"status_quo\",\n",
    "    \"DHA-PPQ_3yrs_then_5day_AL50-ASAQ50\",\n",
    "    \"DHA-PPQ_3yrs_then_AL50-DHAPPQ50\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055186f",
   "metadata": {},
   "source": [
    "Prefilter the data to clear out runs that didn't complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for file in filelist:\n",
    "    months = analysis.get_table(file, \"monthlydata\")\n",
    "    try:\n",
    "        last_month = months[\"id\"].to_list()[-1]\n",
    "    except IndexError:\n",
    "        print(f\"File: {file} is missing data\")\n",
    "        continue\n",
    "    if last_month < 385:\n",
    "        print(f\"File: {file} is missing data for month {last_month}\")\n",
    "        continue\n",
    "    # move the file to the correct location\n",
    "    shutil.move(file, os.path.join(\"good\", os.path.basename(file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7804dcb1",
   "metadata": {},
   "source": [
    "## Create treatment failure plots for all strategies\n",
    "\n",
    "Note: due to incomplete batch runs, some strategies may not have data or have incomplete data. Incomplete data will result in a ValueError when plotting due to a dimension mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de255eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "DATA_SOURCE: str = os.path.join(DATA_ROOT, \"good\")\n",
    "\n",
    "for strategy in strategies:\n",
    "    try:\n",
    "        data = analysis.aggregate_failure_rates(DATA_SOURCE, strategy)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    if data is None:\n",
    "        print(f\"No data found for {strategy} or there was an aggregation error\")\n",
    "        continue\n",
    "    try:\n",
    "        fig, ax = analysis.plot_strategy_treatment_failure(data, strategy.replace(\"_\", \" \").title())\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        plt.close(fig)\n",
    "        continue\n",
    "    plt.savefig(f\"{strategy}.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea73ba",
   "metadata": {},
   "source": [
    "## Violin plots\n",
    "\n",
    "Create a violin plot for a given genotype based on the row in agg_fqy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d13e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "locationid = 1\n",
    "for i, strategy in enumerate(strategies):\n",
    "    try:\n",
    "        agg_fqy = analysis.aggregate_resistant_genome_frequencies(DATA_SOURCE, strategy, \"H\", 325, locationid)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    try:\n",
    "        ax.violinplot(agg_fqy, positions=[i], showmeans=True, orientation=\"horizontal\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Error plotting {strategy}\")\n",
    "        continue\n",
    "title = \"Genotype Frequencies\"  # for Location {locationid}\"\n",
    "if locationid > 0:\n",
    "    title += f\" for Location {locationid}\"\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel(\"Frequency\")\n",
    "ax.set_ylabel(\"Strategy\")\n",
    "ax.set_yticks(range(len(strategies)))\n",
    "ax.set_yticklabels(strategies)\n",
    "plt.savefig(\"genotype_frequencies_violins.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac87aa7",
   "metadata": {},
   "source": [
    "Next we want to create Figure 2 from the [zubpko23 paper](https://mol.ax/pdf/zupko23b.pdf). Rather, than compare treatments, let's just do the results for one treatment per plot. \n",
    "\n",
    "Plot the following:\n",
    "1. Number of treamtment failures plus 90% confidence interval\n",
    "2. Resistant genometypes plus 90% confidence interval\n",
    "3. PfPR2-10 (twelve month smoothed malaria prevelance in children 2-10 years old)\n",
    "\n",
    "Plots are over ten years from when the treatment was started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for strategy in strategies:\n",
    "    try:\n",
    "        fig = analysis.plot_combined_strategy_aggragated_results(DATA_SOURCE, strategy, \"H\", 1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    plt.savefig(f\"{strategy}_combined.png\")\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb604a8",
   "metadata": {},
   "source": [
    "## Calibration efforts\n",
    "\n",
    "Now that we have a handle on creating the useful plots for publication we need to develop a calibration pipeline. The primary calibration point is to relate the beta parameter (rate of infection/biting) with the population size of a given map pixel. This involves a few steps. As a preliminary step, obtain the relevant raster files that contain population data, district mapping values, treatment, and beta rats (pfpr2-10, or a similar name) and place it under `data/<country>`. Calibration data will be stored under `data/<country>/calibration`.\n",
    "\n",
    "Calibration then occurs in two phases. The first phase is generating the simulated data for beta calibration. See `scripts/calibrate.py` for an example but the general process is to use the `configure` command to create various input .yml files that vary a single pixel map's population, access rate, and beta values. The second phase is to then compare and fit this data to the real beta values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425d994",
   "metadata": {},
   "source": [
    "### Raster utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_raster(file: str) -> np.ndarray:\n",
    "    with open(file, \"r\") as f:\n",
    "        data = f.read().splitlines()\n",
    "    metadata = data[:6]\n",
    "    data = data[6:]\n",
    "    # convert the metadata to a dictionary\n",
    "    metadata = {line.split()[0]: float(line.split()[1]) for line in metadata}\n",
    "    raster = np.zeros((int(metadata[\"nrows\"]), int(metadata[\"ncols\"])))\n",
    "    for i, line in enumerate(data):\n",
    "        line = line.split()\n",
    "        line = np.asarray(line, dtype=float)\n",
    "        raster[i, :] = line\n",
    "    # filter metadata['NODATA_value'] from the raster to be np.nan\n",
    "    raster[raster == metadata[\"NODATA_value\"]] = np.nan\n",
    "    return raster, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts, _ = read_raster(\"data/moz/moz_districts.asc\")\n",
    "population, _ = read_raster(\"data/moz/moz_population.asc\")\n",
    "prevalence, _ = read_raster(\"data/moz/moz_pfpr210.asc\")\n",
    "treatment, _ = read_raster(\"data/moz/moz_treatmentseeking.asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "district_names = pd.read_csv(\"data/moz/moz_mapping.csv\", index_col=\"ID\")\n",
    "names = district_names.to_dict()[\"DISTRICT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779510d",
   "metadata": {},
   "source": [
    "#### Plot districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "# define a custom color map for the 11 districts\n",
    "cmap = plt.get_cmap(\"tab20\", 11)\n",
    "# create a new figure\n",
    "fig, ax = plt.subplots()\n",
    "# plot the districts raster\n",
    "ax.imshow(districts, cmap=cmap)\n",
    "ax.set_title(\"Mozambique Districts\")\n",
    "\n",
    "# create legend handles\n",
    "handles = [Patch(color=cmap(i), label=names[i + 1].replace(\"_\", \" \")) for i in range(11)]\n",
    "ax.legend(bbox_to_anchor=(1.75, 1), handles=handles, title=\"Districts\", loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f57e1",
   "metadata": {},
   "source": [
    "#### Plot population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(population, cmap=\"coolwarm\")\n",
    "ax.set_title(\"Population\")\n",
    "fig.colorbar(plt.cm.ScalarMappable(cmap=\"coolwarm\"), ax=ax, label=\"Population Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5b8c6",
   "metadata": {},
   "source": [
    "#### Plot prevalence\n",
    "\n",
    "This is what we'll end up calibrating too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(prevalence, cmap=\"coolwarm\")\n",
    "ax.set_title(\"pfpr 2-10\")\n",
    "fig.colorbar(plt.cm.ScalarMappable(cmap=\"coolwarm\"), ax=ax, label=\"Prevalence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ca7ce",
   "metadata": {},
   "source": [
    "## Run calibration\n",
    "\n",
    "The unknown that we are trying to solve for is the beta value(s). We have _real_ pixel-wise _prevalence_ (pfpr2-10) data that arrises from a given beta. The goal is to generate data that matches closely the real prevalence data by varying the beta value, population size, and access rate for a simulated single pixel. We will first generate the configuration files for the calibration runs here. The below cell is also in the `scripts/calibrate.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893310f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country calibration script\n",
    "from masim_analysis import configure\n",
    "from datetime import date\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from masim_analysis import commands\n",
    "\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "yaml = YAML()\n",
    "\n",
    "# Calibration parameters\n",
    "populations = [10, 25, 50, 75, 100, 150, 200, 250, 300, 400, 500, 750, 1000, 2000, 3000, 4000, 5000, 7500, 10000, 12500, 15000, 20000]\n",
    "betas = [0.001, 0.005, 0.01, 0.0125, 0.015, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.8, 1]\n",
    "access_rates = [0.50, 0.55, 0.60, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "calibration_year = 2022 # This is the year from which we have pfpr data\n",
    "reps = 20\n",
    "# Input parameters\n",
    "name = \"moz\"\n",
    "comparison = date(calibration_year, 1, 1)\n",
    "start = date(calibration_year - 11, 1, 1)\n",
    "end = date(calibration_year + 1, 12, 31)\n",
    "birth_rate = 31.2 / 1000\n",
    "death_rate = [0.049744, 0.064331, 0.064331, 0.064331, 0.064331, 0.00359, 0.00361, 0.00365, 0.00379, 0.00379, 0.133, 0.133, 0.0174, 0.0174 ]\n",
    "age_distribution = [ 0.037, 0.132, 0.161, 0.142, 0.090, 0.086, 0.070, 0.052, 0.044, 0.044, 0.031, 0.041, 0.024, 0.017, 0.013, 0.017 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451cdd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [08:20<00:00, 22.73s/it]\n"
     ]
    }
   ],
   "source": [
    "### Execution ------------------------------------------------\n",
    "execution_control = configure.main(\n",
    "    name,\n",
    "    start.strftime(\"%Y/%m/%d\"),\n",
    "    end.strftime(\"%Y/%m/%d\"),\n",
    "    comparison.strftime(\"%Y/%m/%d\"),\n",
    "    calibration=True,\n",
    ")\n",
    "execution_control[\"birth_rate\"] = birth_rate\n",
    "execution_control[\"death_rate\"] = death_rate\n",
    "execution_control[\"age_distribution\"] = age_distribution\n",
    "execution_control[\"strategy_db\"] = {\n",
    "    0: {\n",
    "        \"name\": \"baseline\",\n",
    "        \"type\": \"MFT\",\n",
    "        \"therapy_ids\": [0],\n",
    "        \"distribution\": [1],\n",
    "    },\n",
    "}\n",
    "execution_control[\"initial_strategy_id\"] = 0\n",
    "\n",
    "execution_control[\"events\"] = [\n",
    "    {\"name\": \"turn_off_mutation\", \"info\": [{\"day\": start.strftime(\"%Y/%m/%d\")}]},\n",
    "]\n",
    "\n",
    "# Generate the configuration files\n",
    "for pop in tqdm(populations):\n",
    "        for access in access_rates:\n",
    "            for beta in betas:\n",
    "                execution_control[\"raster_db\"] = configure.validate_raster_files(\n",
    "                    \"moz\",\n",
    "                    calibration=True,\n",
    "                    calibration_string=f\"{pop}_{access}_{beta}\",\n",
    "                    access_rate=access,\n",
    "                    age_distribution=age_distribution,\n",
    "                    beta=beta,\n",
    "                    population=pop,\n",
    "                )\n",
    "                output_path = os.path.join(\"conf\", name, \"calibration\", f\"cal_{pop}_{access}_{beta}.yml\")\n",
    "                yaml.dump(execution_control, open(output_path, \"w\"))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86288e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 6/22 [00:00<00:00, 27.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands file: moz_10_cmds.txt\n",
      "Job script: moz_10_jobs.sh\n",
      "To submit the job, run: qsub moz_10_jobs.sh\n",
      "Commands file: moz_25_cmds.txt\n",
      "Job script: moz_25_jobs.sh\n",
      "To submit the job, run: qsub moz_25_jobs.sh\n",
      "Commands file: moz_50_cmds.txt\n",
      "Job script: moz_50_jobs.sh\n",
      "To submit the job, run: qsub moz_50_jobs.sh\n",
      "Commands file: moz_75_cmds.txt\n",
      "Job script: moz_75_jobs.sh\n",
      "To submit the job, run: qsub moz_75_jobs.sh\n",
      "Commands file: moz_100_cmds.txt\n",
      "Job script: moz_100_jobs.sh\n",
      "To submit the job, run: qsub moz_100_jobs.sh\n",
      "Commands file: moz_150_cmds.txt\n",
      "Job script: moz_150_jobs.sh\n",
      "To submit the job, run: qsub moz_150_jobs.sh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 12/22 [00:00<00:00, 28.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands file: moz_200_cmds.txt\n",
      "Job script: moz_200_jobs.sh\n",
      "To submit the job, run: qsub moz_200_jobs.sh\n",
      "Commands file: moz_250_cmds.txt\n",
      "Job script: moz_250_jobs.sh\n",
      "To submit the job, run: qsub moz_250_jobs.sh\n",
      "Commands file: moz_300_cmds.txt\n",
      "Job script: moz_300_jobs.sh\n",
      "To submit the job, run: qsub moz_300_jobs.sh\n",
      "Commands file: moz_400_cmds.txt\n",
      "Job script: moz_400_jobs.sh\n",
      "To submit the job, run: qsub moz_400_jobs.sh\n",
      "Commands file: moz_500_cmds.txt\n",
      "Job script: moz_500_jobs.sh\n",
      "To submit the job, run: qsub moz_500_jobs.sh\n",
      "Commands file: moz_750_cmds.txt\n",
      "Job script: moz_750_jobs.sh\n",
      "To submit the job, run: qsub moz_750_jobs.sh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 15/22 [00:00<00:00, 26.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands file: moz_1000_cmds.txt\n",
      "Job script: moz_1000_jobs.sh\n",
      "To submit the job, run: qsub moz_1000_jobs.sh\n",
      "Commands file: moz_2000_cmds.txt\n",
      "Job script: moz_2000_jobs.sh\n",
      "To submit the job, run: qsub moz_2000_jobs.sh\n",
      "Commands file: moz_3000_cmds.txt\n",
      "Job script: moz_3000_jobs.sh\n",
      "To submit the job, run: qsub moz_3000_jobs.sh\n",
      "Commands file: moz_4000_cmds.txt\n",
      "Job script: moz_4000_jobs.sh\n",
      "To submit the job, run: qsub moz_4000_jobs.sh\n",
      "Commands file: moz_5000_cmds.txt\n",
      "Job script: moz_5000_jobs.sh\n",
      "To submit the job, run: qsub moz_5000_jobs.sh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 25.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands file: moz_7500_cmds.txt\n",
      "Job script: moz_7500_jobs.sh\n",
      "To submit the job, run: qsub moz_7500_jobs.sh\n",
      "Commands file: moz_10000_cmds.txt\n",
      "Job script: moz_10000_jobs.sh\n",
      "To submit the job, run: qsub moz_10000_jobs.sh\n",
      "Commands file: moz_12500_cmds.txt\n",
      "Job script: moz_12500_jobs.sh\n",
      "To submit the job, run: qsub moz_12500_jobs.sh\n",
      "Commands file: moz_15000_cmds.txt\n",
      "Job script: moz_15000_jobs.sh\n",
      "To submit the job, run: qsub moz_15000_jobs.sh\n",
      "Commands file: moz_20000_cmds.txt\n",
      "Job script: moz_20000_jobs.sh\n",
      "To submit the job, run: qsub moz_20000_jobs.sh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the command and job files\n",
    "for pop in tqdm(populations):\n",
    "    with open(f\"{name}_{pop}_cmds.txt\", \"w\") as f:\n",
    "        for access in access_rates:\n",
    "            for beta in betas:\n",
    "                for j in range(reps):\n",
    "                    f.write(f\"./bin/MaSim -i ./conf/{name}/calibration/cal_{pop}_{access}_{beta}.yml -o ./output/{name}/calibration/cal_{pop}_{access}_{beta}_ -r SQLiteDistrictReporter -j {j+1}\\n\")\n",
    "    commands.generate_job_file(f\"{name}_{pop}_cmds.txt\", f\"{name}_{pop}_jobs\", cores_override = 28, nodes_override = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cfc524",
   "metadata": {},
   "source": [
    "### Load simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masim_analysis import analysis\n",
    "import pandas as pd\n",
    "\n",
    "base_file_path = os.path.join(\"output\", name, \"calibration\")\n",
    "summary = pd.DataFrame(columns=[\"population\", \"access_rate\", \"beta\", \"iteration\", \"pfprunder5\", \"pfpr2to10\", \"pfprall\"])\n",
    "\n",
    "year_start = comparison.strftime(\"%Y-%m-%d\")\n",
    "year_end = (comparison + pd.DateOffset(years=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "for pop in populations:\n",
    "    for access in access_rates:\n",
    "        for beta in betas:\n",
    "            for i in range(10):       \n",
    "                filename = f\"cal_{pop}_{access}_{beta}_monthly_data_{i}\"\n",
    "                file = os.path.join(base_file_path, f\"{filename}.db\") \n",
    "                \n",
    "                try:\n",
    "                    months = analysis.get_table(file, \"monthlydata\")\n",
    "                    monthlysitedata = analysis.get_table(file, \"monthlysitedata\")\n",
    "                except FileNotFoundError as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "                data = pd.merge(monthlysitedata, months, left_on=\"monthlydataid\", right_on=\"id\")\n",
    "                data['date'] = pd.to_datetime(data['modeltime'], unit='s')\n",
    "\n",
    "                summary.loc[filename] = data[(data['date'] >= comparison.strftime(\"%Y-%m-%d\")) & (data['date'] < year_end)][['pfprunder5', 'pfpr2to10', 'pfprall']].mean()\n",
    "                summary.loc[filename, \"population\"] = pop\n",
    "                summary.loc[filename, \"access_rate\"] = access\n",
    "                summary.loc[filename, \"beta\"] = beta\n",
    "                summary.loc[filename, \"iteration\"] = int(i)\n",
    "\n",
    "summary.to_csv(f\"{base_file_path}/calibration_summary.csv\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38e6f1",
   "metadata": {},
   "source": [
    "Now we'll do some basic plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550dbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(summary, col=\"access_rate\", row=\"population\", margin_titles=True)\n",
    "g.map(plt.scatter, \"beta\", \"pfpr2to10\")\n",
    "g.set_axis_labels\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1baabc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
