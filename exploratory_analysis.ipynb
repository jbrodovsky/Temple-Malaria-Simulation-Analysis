{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac53736-3a00-443d-9120-a37ee038a592",
   "metadata": {},
   "source": [
    "# MaSim Analysis and Interaction\n",
    "\n",
    "This notebook is used for testing and interacting with the output from MaSim as well as working with the input data. Once sufficiently developed, code from this notebook is converted to a Python module or script and moved into the `src/masim_analysis` or `scripts` directory. The source folder is for code that is intended to be used in other code, while the scripts folder is for code that is intended to be run from the command line. The source code may also define command line tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b639d9d9",
   "metadata": {},
   "source": [
    "## Some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08daa6a0-f860-43e1-be4f-cc107e0a09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from masim_analysis import analysis\n",
    "\n",
    "# DATA_ROOT: str = os.path.join(\"G:\\\\\", \"My Drive\")\n",
    "DATA_ROOT: str = os.path.join(\"/\", \"home\", \"james\", \"Code\", \"Temple-Malaria-Simulation-Analysis\")\n",
    "# DATA_SOURCE: str = os.path.join(DATA_ROOT, \"Code\", \"output_old\")\n",
    "DATA_SOURCE: str = os.path.join(DATA_ROOT, \"output2\", \"rwa\")\n",
    "filelist = glob.glob(os.path.join(DATA_SOURCE, \"*.db\"))\n",
    "\n",
    "strategies = [\n",
    "    \"AL5\",\n",
    "    \"AL4\",\n",
    "    \"AL25-ASAQ75\",\n",
    "    \"AL25-DHAPPQ75\",\n",
    "    \"AL50-ASAQ50\",\n",
    "    \"AL50-DHAPPQ50\",\n",
    "    \"AL75-ASAQ25\",\n",
    "    \"AL75-DHAPPQ25\",\n",
    "    \"ASAQ\",\n",
    "    \"ASAQ25-DHAPPQ75\",\n",
    "    \"ASAQ50-DHAPPQ50\",\n",
    "    \"ASAQ75-DHAPPQ25\",\n",
    "    \"DHA-PPQ\",\n",
    "    \"status_quo\",\n",
    "    \"DHA-PPQ_3yrs_then_5day_AL50-ASAQ50\",\n",
    "    \"DHA-PPQ_3yrs_then_AL50-DHAPPQ50\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055186f",
   "metadata": {},
   "source": [
    "Prefilter the data to clear out runs that didn't complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for file in filelist:\n",
    "    months = analysis.get_table(file, \"monthlydata\")\n",
    "    try:\n",
    "        last_month = months[\"id\"].to_list()[-1]\n",
    "    except IndexError:\n",
    "        print(f\"File: {file} is missing data\")\n",
    "        continue\n",
    "    if last_month < 385:\n",
    "        print(f\"File: {file} is missing data for month {last_month}\")\n",
    "        continue\n",
    "    # move the file to the correct location\n",
    "    shutil.move(file, os.path.join(\"good\", os.path.basename(file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7804dcb1",
   "metadata": {},
   "source": [
    "## Create treatment failure plots for all strategies\n",
    "\n",
    "Note: due to incomplete batch runs, some strategies may not have data or have incomplete data. Incomplete data will result in a ValueError when plotting due to a dimension mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de255eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "DATA_SOURCE: str = os.path.join(DATA_ROOT, \"good\")\n",
    "\n",
    "for strategy in strategies:\n",
    "    try:\n",
    "        data = analysis.aggregate_failure_rates(DATA_SOURCE, strategy)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    if data is None:\n",
    "        print(f\"No data found for {strategy} or there was an aggregation error\")\n",
    "        continue\n",
    "    try:\n",
    "        fig, ax = analysis.plot_strategy_treatment_failure(data, strategy.replace(\"_\", \" \").title())\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        plt.close(fig)\n",
    "        continue\n",
    "    plt.savefig(f\"{strategy}.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea73ba",
   "metadata": {},
   "source": [
    "## Violin plots\n",
    "\n",
    "Create a violin plot for a given genotype based on the row in agg_fqy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d13e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "locationid = 1\n",
    "for i, strategy in enumerate(strategies):\n",
    "    try:\n",
    "        agg_fqy = analysis.aggregate_resistant_genome_frequencies(DATA_SOURCE, strategy, \"H\", 325, locationid)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    try:\n",
    "        ax.violinplot(agg_fqy, positions=[i], showmeans=True, orientation=\"horizontal\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Error plotting {strategy}\")\n",
    "        continue\n",
    "title = \"Genotype Frequencies\"  # for Location {locationid}\"\n",
    "if locationid > 0:\n",
    "    title += f\" for Location {locationid}\"\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel(\"Frequency\")\n",
    "ax.set_ylabel(\"Strategy\")\n",
    "ax.set_yticks(range(len(strategies)))\n",
    "ax.set_yticklabels(strategies)\n",
    "plt.savefig(\"genotype_frequencies_violins.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac87aa7",
   "metadata": {},
   "source": [
    "Next we want to create Figure 2 from the [zubpko23 paper](https://mol.ax/pdf/zupko23b.pdf). Rather, than compare treatments, let's just do the results for one treatment per plot. \n",
    "\n",
    "Plot the following:\n",
    "1. Number of treamtment failures plus 90% confidence interval\n",
    "2. Resistant genometypes plus 90% confidence interval\n",
    "3. PfPR2-10 (twelve month smoothed malaria prevelance in children 2-10 years old)\n",
    "\n",
    "Plots are over ten years from when the treatment was started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for strategy in strategies:\n",
    "    try:\n",
    "        fig = analysis.plot_combined_strategy_aggragated_results(DATA_SOURCE, strategy, \"H\", 1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    plt.savefig(f\"{strategy}_combined.png\")\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb604a8",
   "metadata": {},
   "source": [
    "## Calibration efforts\n",
    "\n",
    "Now that we have a handle on creating the useful plots for publication we need to develop a calibration pipeline. The primary calibration point is to relate the beta parameter (rate of infection/biting) with the population size of a given map pixel. This involves a few steps. As a preliminary step, obtain the relevant raster files that contain population data, district mapping values, treatment, and beta rats (pfpr2-10, or a similar name) and place it under `data/<country>`. Calibration data will be stored under `data/<country>/calibration`.\n",
    "\n",
    "Calibration then occurs in two phases. The first phase is generating the simulated data for beta calibration. See `scripts/calibrate.py` for an example but the general process is to use the `configure` command to create various input .yml files that vary a single pixel map's population, access rate, and beta values. The second phase is to then compare and fit this data to the real beta values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425d994",
   "metadata": {},
   "source": [
    "### Raster utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3bea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_raster(file: str) -> np.ndarray:\n",
    "    with open(file, \"r\") as f:\n",
    "        data = f.read().splitlines()\n",
    "    metadata = data[:6]\n",
    "    data = data[6:]\n",
    "    # convert the metadata to a dictionary\n",
    "    metadata = {line.split()[0]: float(line.split()[1]) for line in metadata}\n",
    "    raster = np.zeros((int(metadata[\"nrows\"]), int(metadata[\"ncols\"])))\n",
    "    for i, line in enumerate(data):\n",
    "        line = line.split()\n",
    "        line = np.asarray(line, dtype=float)\n",
    "        raster[i, :] = line\n",
    "    # filter metadata['NODATA_value'] from the raster to be np.nan\n",
    "    raster[raster == metadata[\"NODATA_value\"]] = np.nan\n",
    "    return raster, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f8c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts, _ = read_raster(\"data/moz/moz_districts.asc\")\n",
    "population, _ = read_raster(\"data/moz/moz_population.asc\")\n",
    "prevalence, _ = read_raster(\"data/moz/moz_pfpr210.asc\")\n",
    "treatment, _ = read_raster(\"data/moz/moz_treatmentseeking.asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be012d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_rates = np.unique(treatment)\n",
    "access_rates = access_rates[~np.isnan(access_rates)]\n",
    "access_rates = np.sort(access_rates)\n",
    "access_rates = access_rates.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebaebe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0.  ,  14320.92,  28641.84,  42962.76,  57283.68,  71604.6 ,\n",
       "        85925.52, 100246.44, 114567.36, 128888.28, 143209.2 , 157530.12,\n",
       "       171851.04, 186171.96, 200492.88, 214813.8 , 229134.72, 243455.64,\n",
       "       257776.56, 272097.48, 286418.4 , 300739.32, 315060.24, 329381.16,\n",
       "       343702.08, 358023.  ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populations = np.unique(population)\n",
    "populations = populations[~np.isnan(populations)]\n",
    "_, pop_bins = np.histogram(populations, bins=25)\n",
    "pop_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bdc5cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = [10, 20, 30, 40, 50, 75, 100, 250, 500, 1000, 2000, 5000, 10000, 15000, 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "district_names = pd.read_csv(\"data/moz/moz_mapping.csv\", index_col=\"ID\")\n",
    "names = district_names.to_dict()[\"DISTRICT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779510d",
   "metadata": {},
   "source": [
    "#### Plot districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "# define a custom color map for the 11 districts\n",
    "cmap = plt.get_cmap(\"tab20\", 11)\n",
    "# create a new figure\n",
    "fig, ax = plt.subplots()\n",
    "# plot the districts raster\n",
    "ax.imshow(districts, cmap=cmap)\n",
    "ax.set_title(\"Mozambique Districts\")\n",
    "\n",
    "# create legend handles\n",
    "handles = [Patch(color=cmap(i), label=names[i + 1].replace(\"_\", \" \")) for i in range(11)]\n",
    "ax.legend(bbox_to_anchor=(1.75, 1), handles=handles, title=\"Districts\", loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f57e1",
   "metadata": {},
   "source": [
    "#### Plot population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(population, cmap=\"coolwarm\")\n",
    "ax.set_title(\"Population\")\n",
    "fig.colorbar(plt.cm.ScalarMappable(cmap=\"coolwarm\"), ax=ax, label=\"Population Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5b8c6",
   "metadata": {},
   "source": [
    "#### Plot prevalence\n",
    "\n",
    "This is what we'll end up calibrating too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(prevalence, cmap=\"coolwarm\")\n",
    "ax.set_title(\"pfpr 2-10\")\n",
    "fig.colorbar(plt.cm.ScalarMappable(cmap=\"coolwarm\"), ax=ax, label=\"Prevalence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ca7ce",
   "metadata": {},
   "source": [
    "## Run calibration\n",
    "\n",
    "The unknown that we are trying to solve for is the beta value(s). We have _real_ pixel-wise _prevalence_ (pfpr2-10) data that arrises from a given beta. The goal is to generate data that matches closely the real prevalence data by varying the beta value, population size, and access rate for a simulated single pixel. We will first generate the configuration files for the calibration runs here. The below cell is also in the `scripts/calibrate.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893310f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country calibration script\n",
    "from masim_analysis import configure\n",
    "from datetime import date\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from masim_analysis import commands\n",
    "\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "yaml = YAML()\n",
    "\n",
    "# Calibration parameters\n",
    "# populations = [10, 25, 50, 75, 100, 150, 200, 250, 300, 400, 500, 750, 1000, 2000, 3000, 4000, 5000, 7500, 10000, 12500, 15000, 20000]\n",
    "betas = [0.001, 0.005, 0.01, 0.0125, 0.015, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.8, 1]\n",
    "# access_rates = [0.50, 0.55, 0.60, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "calibration_year = 2022 # This is the year from which we have pfpr data\n",
    "reps = 20\n",
    "# Input parameters\n",
    "name = \"moz\"\n",
    "comparison = date(calibration_year, 1, 1)\n",
    "start = date(calibration_year - 11, 1, 1)\n",
    "end = date(calibration_year + 1, 12, 31)\n",
    "birth_rate = 31.2 / 1000\n",
    "death_rate = [0.049744, 0.064331, 0.064331, 0.064331, 0.064331, 0.00359, 0.00361, 0.00365, 0.00379, 0.00379, 0.133, 0.133, 0.0174, 0.0174 ]\n",
    "age_distribution = [ 0.037, 0.132, 0.161, 0.142, 0.090, 0.086, 0.070, 0.052, 0.044, 0.044, 0.031, 0.041, 0.024, 0.017, 0.013, 0.017 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cdd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "### Execution ------------------------------------------------\n",
    "execution_control = configure.main(\n",
    "    name,\n",
    "    start.strftime(\"%Y/%m/%d\"),\n",
    "    end.strftime(\"%Y/%m/%d\"),\n",
    "    comparison.strftime(\"%Y/%m/%d\"),\n",
    "    calibration=True,\n",
    ")\n",
    "execution_control[\"birth_rate\"] = birth_rate\n",
    "execution_control[\"death_rate\"] = death_rate\n",
    "execution_control[\"age_distribution\"] = age_distribution\n",
    "execution_control[\"strategy_db\"] = {\n",
    "    0: {\n",
    "        \"name\": \"baseline\",\n",
    "        \"type\": \"MFT\",\n",
    "        \"therapy_ids\": [0],\n",
    "        \"distribution\": [1],\n",
    "    },\n",
    "}\n",
    "execution_control[\"initial_strategy_id\"] = 0\n",
    "\n",
    "execution_control[\"events\"] = [\n",
    "    {\"name\": \"turn_off_mutation\", \"info\": [{\"day\": start.strftime(\"%Y/%m/%d\")}]},\n",
    "]\n",
    "\n",
    "# Generate the configuration files\n",
    "for pop in tqdm(populations):\n",
    "        for access in access_rates:\n",
    "            for beta in betas:\n",
    "                execution_control[\"raster_db\"] = configure.validate_raster_files(\n",
    "                    \"moz\",\n",
    "                    calibration=True,\n",
    "                    calibration_string=f\"{pop}_{access}_{beta}\",\n",
    "                    access_rate=access,\n",
    "                    age_distribution=age_distribution,\n",
    "                    beta=beta,\n",
    "                    population=pop,\n",
    "                )\n",
    "                output_path = os.path.join(\"conf\", name, \"calibration\", f\"cal_{pop}_{access}_{beta}.yml\")\n",
    "                yaml.dump(execution_control, open(output_path, \"w\"))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86288e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the command and job files\n",
    "for pop in tqdm(populations):\n",
    "    with open(f\"{name}_{pop}_cmds.txt\", \"w\") as f:\n",
    "        for access in access_rates:\n",
    "            for beta in betas:            \n",
    "                for j in range(reps):\n",
    "                    f.write(f\"./bin/MaSim -i ./conf/{name}/calibration/cal_{pop}_{access}_{beta}.yml -o ./output/{name}/calibration/cal_{pop}_{access}_{beta}_ -r SQLiteDistrictReporter -j {j+1}\\n\")\n",
    "    commands.generate_job_file(f\"{name}_{pop}_cmds.txt\", f\"{name}_{pop}_jobs\", cores_override = 28, nodes_override = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cfc524",
   "metadata": {},
   "source": [
    "### Load simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masim_analysis import analysis\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "base_file_path = os.path.join(\"output\", name, \"calibration\")\n",
    "summary = pd.DataFrame(columns=[\"population\", \"access_rate\", \"beta\", \"iteration\", \"pfprunder5\", \"pfpr2to10\", \"pfprall\"])\n",
    "\n",
    "year_start = comparison.strftime(\"%Y-%m-%d\")\n",
    "year_end = (comparison + pd.DateOffset(years=1)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process missing jobs\n",
    "for pop in tqdm(populations):\n",
    "    for access in access_rates:\n",
    "        for beta in betas:\n",
    "            for i in range(1, 11):       \n",
    "                filename = f\"cal_{pop}_{access}_{beta}_monthly_data_{i}\"\n",
    "                file = os.path.join(base_file_path, f\"{filename}.db\") \n",
    "                try:\n",
    "                    months = analysis.get_table(file, \"monthlydata\")\n",
    "                    monthlysitedata = analysis.get_table(file, \"monthlysitedata\")\n",
    "                except FileNotFoundError as e:\n",
    "                    with open(f\"missing_calibration_runs_{pop}_{access}.txt\", \"a\") as f:\n",
    "                        # f.write(f\"{e}\\n\")\n",
    "                        f.write(f\"./bin/MaSim -i ./conf/{name}/calibration/cal_{pop}_{access}_{beta}.yml -o ./output/{name}/calibration/cal_{pop}_{access}_{beta}_ -r SQLiteDistrictReporter -j {i+1}\\n\")\n",
    "\n",
    "                    if not os.path.exists(f\"missing_calibration_runs_{pop}_{access}_job.sh\"):\n",
    "                          with open(f\"missing_calibration_runs_{pop}_{access}_job.sh\", \"w\") as f:\n",
    "                              f.write(\"#!/bin/sh\\n\")\n",
    "                              f.write(\"#PBS -l walltime=48:00:00\\n\")\n",
    "                              f.write(\"#PBS -N MyJob\\n\")\n",
    "                              f.write(\"#PBS -q normal\\n\")\n",
    "                              f.write(\"#PBS -l nodes=4:ppn=28\\n\")\n",
    "                              f.write(\"cd $PBS_O_WORKDIR\\n\")\n",
    "                              f.write(f\"torque-launch missing_calibration_runs_{pop}_{access}.txt\\n\")\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process summary\n",
    "for pop in tqdm(populations):\n",
    "    for access in access_rates:\n",
    "        for beta in betas:\n",
    "            for i in range(1, 11):       \n",
    "                filename = f\"cal_{pop}_{access}_{beta}_monthly_data_{i}\"\n",
    "                file = os.path.join(base_file_path, f\"{filename}.db\") \n",
    "                try:\n",
    "                    months = analysis.get_table(file, \"monthlydata\")\n",
    "                    monthlysitedata = analysis.get_table(file, \"monthlysitedata\")\n",
    "                except FileNotFoundError as e:\n",
    "                    print(f\"File not found: {e}\")\n",
    "                    continue\n",
    "                data = pd.merge(monthlysitedata, months, left_on=\"monthlydataid\", right_on=\"id\")\n",
    "                data['date'] = pd.to_datetime(data['modeltime'], unit='s')\n",
    "\n",
    "                summary.loc[filename] = data[(data['date'] >= comparison.strftime(\"%Y-%m-%d\")) & (data['date'] < year_end)][['pfprunder5', 'pfpr2to10', 'pfprall']].mean()\n",
    "                summary.loc[filename, \"population\"] = pop\n",
    "                summary.loc[filename, \"access_rate\"] = access\n",
    "                summary.loc[filename, \"beta\"] = beta\n",
    "                summary.loc[filename, \"iteration\"] = int(i)\n",
    "\n",
    "summary.to_csv(f\"{base_file_path}/calibration_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38e6f1",
   "metadata": {},
   "source": [
    "Now we'll do some basic plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "name = \"moz\"\n",
    "base_file_path = os.path.join(\"output\", name, \"calibration\")\n",
    "summary = pd.read_csv(f\"{base_file_path}/calibration_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea836a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ae421",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = summary[[\"population\", \"access_rate\", \"beta\", \"iteration\", \"pfpr2to10\"]].copy()\n",
    "means = means.groupby([\"population\", \"access_rate\", \"beta\"])['pfpr2to10'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550dbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(means, col=\"access_rate\", row=\"population\", margin_titles=True)\n",
    "g.map(plt.scatter, \"beta\", \"pfpr2to10\")\n",
    "g.set_axis_labels\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab154bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "means.to_csv(f\"{base_file_path}/calibration_means.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abc4e2",
   "metadata": {},
   "source": [
    "# Curve fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve Fitting (liear and polynomial regression models)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "name = \"moz\"\n",
    "base_file_path = os.path.join(\"output\", name, \"calibration\")\n",
    "means = pd.read_csv(f\"{base_file_path}/calibration_means.csv\")\n",
    "populations = means['population'].unique()\n",
    "access_rates = means['access_rate'].unique()\n",
    "betas = means['beta'].unique()\n",
    "group = means[(means['population'] == 100) & (means['access_rate'] == 0.65)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5886365",
   "metadata": {},
   "source": [
    "## Normal axis fit\n",
    "\n",
    "We're looking to fit the pfpr to beta relationship so that we can then use the real pfpr value from the raster data to determine the beta value. So, given a specific pixel's population, pfpr, and access rate (treatmentseeking?) calculate the beta value from this fitting method.\n",
    "\n",
    "Start using linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine grid size\n",
    "num_rows = len(populations)\n",
    "num_cols = len(access_rates)\n",
    "\n",
    "# Create subplots grid\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(4 * num_cols, 4 * num_rows), sharex=True, sharey=True)\n",
    "\n",
    "# Ensure axes is always a 2D list for consistency\n",
    "if num_rows == 1:\n",
    "    axes = np.array([axes])  # Convert to 2D array\n",
    "if num_cols == 1:\n",
    "    axes = np.array([[ax] for ax in axes])  # Convert to 2D array\n",
    "    \n",
    "# Perform regression for each (Population, TreatmentAccess) group\n",
    "for i, population in enumerate(populations):\n",
    "    for j, treatment_access in enumerate(access_rates):\n",
    "        ax = axes[i, j]  # Select subplot location\n",
    "        \n",
    "        # Filter the data for the current Population and TreatmentAccess\n",
    "        group = means[(means['population'] == population) & (means['access_rate'] == treatment_access)]\n",
    "        \n",
    "        if group.empty:\n",
    "            ax.set_visible(False)  # Hide empty plots\n",
    "            continue\n",
    "\n",
    "        group = group.dropna(axis=0) # drop any row in a nan column\n",
    "        \n",
    "        X = group[['beta']].values \n",
    "        y = group['pfpr2to10'].values  \n",
    "\n",
    "        # 1. Linear Regression\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # 2. Polynomial Regression (degree 3)\n",
    "        poly_model3 = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
    "        poly_model3.fit(X, y)\n",
    "\n",
    "        # 3. Polynomial Regression (degree 5)\n",
    "        poly_model5 = make_pipeline(PolynomialFeatures(5), LinearRegression())\n",
    "        poly_model5.fit(X, y)\n",
    "\n",
    "        # 4. Spline Regression\n",
    "        #spline_model = UnivariateSpline(group['beta'], group['pfpr2to10'], s=50)\n",
    "\n",
    "        # Plot regression\n",
    "        sns.scatterplot(x=group['beta'], y=group['pfpr2to10'], ax=ax, label=\"Data\", color='black')\n",
    "        ax.plot(group['beta'], model.predict(X), color='red', linestyle=\"dashed\", label=\"Linear\")\n",
    "        ax.plot(group['beta'], poly_model3.predict(X), color='blue', linestyle=\"dashed\", label=\"Poly (3)\")\n",
    "        ax.plot(group['beta'], poly_model5.predict(X), color='green', linestyle=\"dashed\", label=\"Poly (5)\")\n",
    "        #ax.plot(group['Beta'], spline_model(X), color='purple', linestyle=\"dashed\", label=\"Spline\")\n",
    "\n",
    "        # Setting titles & labels\n",
    "        ax.set_title(f\"Population : {population}, Access : {treatment_access}\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"pfpr2to10\")  \n",
    "        if i == num_rows - 1:\n",
    "            ax.set_xlabel(\"Beta\")  \n",
    "        ax.legend(fontsize=7)\n",
    "\n",
    "# Adjust layout\n",
    "plt.suptitle(\"Curve Fitting by Population & Treatment Access\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3310a37",
   "metadata": {},
   "source": [
    "Now we'll do a logarithemic fit for the beta value and attempt to fit a sigmoid curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit \n",
    "import numpy as np\n",
    "\n",
    "# Define sigmoid function\n",
    "def sigmoid_fit(x, a, b, c):\n",
    "    return a / (1 + np.exp(-b * (x - c)))\n",
    "\n",
    "# Function to find Beta values corresponding to an array of pfpr values\n",
    "def find_beta(pfpr_target, linear_model, popt, pfpr_cutoff):  \n",
    "    pfpr_target = np.array(pfpr_target)  # Ensure input is a NumPy array\n",
    "    beta_values = np.zeros_like(pfpr_target, dtype=np.float64)  # Placeholder for results\n",
    "\n",
    "    # Linear region: pfpr_target < cutoff\n",
    "    mask_linear = pfpr_target < pfpr_cutoff\n",
    "    #print(pfpr_target, pfpr_cutoff)\n",
    "    #print(\"any mask linear: \", np.any(mask_linear))\n",
    "    if np.any(mask_linear):\n",
    "        beta_log_linear = (pfpr_target[mask_linear] - linear_model.intercept_) / linear_model.coef_[0]\n",
    "        beta_values[mask_linear] = 10**(beta_log_linear)  # Convert back from log-space\n",
    "\n",
    "    # Sigmoid region: pfpr_target >= cutoff\n",
    "    mask_sigmoid = pfpr_target >= pfpr_cutoff\n",
    "    if np.any(mask_sigmoid):\n",
    "        a, b, c = popt\n",
    "        beta_log_sigmoid = c - (1 / b) * np.log(a / pfpr_target[mask_sigmoid] - 1)\n",
    "        beta_values[mask_sigmoid] = 10**(beta_log_sigmoid)  # Convert back from log-space\n",
    "\n",
    "    return beta_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608eeae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine grid size\n",
    "num_rows = len(populations)\n",
    "num_cols = len(access_rates)\n",
    "\n",
    "# Create subplots grid\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(4 * num_cols, 4 * num_rows), sharex=True, sharey=True)\n",
    "\n",
    "# Ensure axes is always a 2D list for consistency\n",
    "if num_rows == 1:\n",
    "    axes = np.array([axes])  # Convert to 2D array\n",
    "if num_cols == 1:\n",
    "    axes = np.array([[ax] for ax in axes])  # Convert to 2D array\n",
    "\n",
    "# Define cutoff based on pfpr2to10_mean\n",
    "pfpr_cutoff = 0.0  # Set the desired cutoff for pfpr2to10_mean\n",
    "models_map = {} #stores trained model for every parameter configuration\n",
    "\n",
    "# Perform regression for each (Population, TreatmentAccess) group\n",
    "for i, population in enumerate(populations):\n",
    "    for j, treatment_access in enumerate(access_rates):\n",
    "        ax = axes[i, j]  # Select subplot location\n",
    "        \n",
    "        # Filter the data for the current Population and TreatmentAccess\n",
    "        #group = df_final[(df_final['Population'] == population) & (df_final['TreatmentAccess'] == treatment_access)]\n",
    "        group = means[(means['population'] == population) & (means['access_rate'] == treatment_access)]\n",
    "        group['pfpr2to10'] = group['pfpr2to10'].values / 100\n",
    "        group['beta'] = np.log10(group['beta'].values)\n",
    "        \n",
    "        if group.empty:\n",
    "            ax.set_visible(False)  # Hide empty plots\n",
    "            continue\n",
    "        \n",
    "        X = group['beta'].values  # Log of Predictor (Beta)\n",
    "        y = group['pfpr2to10'].values  # Response variable\n",
    "        \n",
    "        # Determine cutoff Beta based on pfpr2to10_mean\n",
    "        if any(y < pfpr_cutoff):\n",
    "            cutoff_beta = np.max(X[y < pfpr_cutoff])  # Largest Beta where pfpr2to10_mean <= cutoff\n",
    "        else:\n",
    "            cutoff_beta = float('-inf')  # No cutoff\n",
    "        \n",
    "        # # Linear Regression on data before cutoff\n",
    "        # mask_linear = X.ravel() < cutoff_beta\n",
    "        # #print(\"mask_linear\", mask_linear)\n",
    "        # if np.sum(mask_linear) > 1:\n",
    "        #     X_linear = X[mask_linear].reshape(-1, 1)\n",
    "        #     y_linear = y[mask_linear]\n",
    "        #     linear_model = LinearRegression()\n",
    "        #     linear_model.fit(X_linear, y_linear)\n",
    "        # else:\n",
    "        #     linear_model = None\n",
    "        \n",
    "        # Sigmoid Regression on data after cutoff\n",
    "        mask_sigmoid = X.ravel() >= cutoff_beta\n",
    "        \n",
    "        if np.sum(mask_sigmoid) > 1:\n",
    "            X_sigmoid = X[mask_sigmoid].flatten()\n",
    "            y_sigmoid = y[mask_sigmoid]\n",
    "            try:\n",
    "                popt, _ = curve_fit(sigmoid_fit, X_sigmoid, y_sigmoid, maxfev=10000)\n",
    "            except TypeError as e:\n",
    "                print(f\"Error in curve_fit: {e} for population {population} and treatment access {treatment_access}\")\n",
    "                popt = None\n",
    "                continue \n",
    "            except ValueError as e:\n",
    "                print(f\"Error in curve_fit: {e} for population {population} and treatment access {treatment_access}\")\n",
    "                popt = None\n",
    "                continue\n",
    "        else:\n",
    "            popt = None\n",
    "            \n",
    "        models_map[(population, treatment_access)] = popt #(linear_model, popt)\n",
    "        \n",
    "        # Predictions\n",
    "        pfpr_targets = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "        #pfpr_targets = np.linspace(0.01, 1, 99).reshape(-1, 1) # To avoid divide by 0 error\n",
    "        \n",
    "        X_plot = find_beta(pfpr_targets, None, popt, pfpr_cutoff)\n",
    "        \n",
    "        #X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "        \n",
    "        ax.set_xscale('log')\n",
    "        \n",
    "        # sns.scatterplot(x=np.exp(group['Beta']), y=group['pfpr2to10_mean'], ax=ax, label=\"Data\", color='black')\n",
    "        sns.scatterplot(x=10**(group['beta']), y=group['pfpr2to10'], ax=ax, label=\"Data\", color='black')\n",
    "        ax.plot(X_plot,pfpr_targets, color='red')\n",
    "    \n",
    "        # Titles & Labels\n",
    "        ax.set_title(f\"Pop {population}, Access {treatment_access}\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"pfpr2to10_mean\")  # Label only on first column\n",
    "        if i == num_rows - 1:\n",
    "            ax.set_xlabel(\"Beta\")  # Label only on last row\n",
    "        ax.legend(fontsize=7)\n",
    "        \n",
    "# Adjust layout\n",
    "plt.suptitle(\"Curve Fitting for beta vs pfpr2to10 by Population & Treatment Access\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a147c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263f19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
